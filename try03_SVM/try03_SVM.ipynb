{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision.transforms as tr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/kbj/Downloads/data/train/x/'\n",
    "data_train_x_list = os.listdir('C:/Users/kbj/Downloads/data/train/x/')\n",
    "path = 'C:/Users/kbj/Downloads/data/train/x/'\n",
    "x_train_mean = np.array([])\n",
    "x_train_var = np.array([])\n",
    "x_train_std = np.array([])\n",
    "x_train_max = np.array([])\n",
    "x_train_min = np.array([])\n",
    "\n",
    "for i in data_train_x_list:\n",
    "    df = pd.read_csv(path+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    x_train_mean = np.append(x_train_mean, mean)\n",
    "    x_train_var = np.append(x_train_var, var)\n",
    "    x_train_std = np.append(x_train_std, std)\n",
    "    x_train_max = np.append(x_train_max, max)\n",
    "    x_train_min = np.append(x_train_min, min)\n",
    "\n",
    "x_train_feature = np.concatenate((x_train_mean.reshape(-1,1), x_train_var.reshape(-1,1), x_train_std.reshape(-1,1), x_train_max.reshape(-1,1), x_train_min.reshape(-1,1)), axis=1)\n",
    "x_train_feature.shape\n",
    "\n",
    "path = 'C:/Users/kbj/Downloads/data/train/y/'\n",
    "data_train_y_list = os.listdir('C:/Users/kbj/Downloads/data/train/y/')\n",
    "path = 'C:/Users/kbj/Downloads/data/train/y/'\n",
    "y_train_mean = np.array([])\n",
    "y_train_var = np.array([])\n",
    "y_train_std = np.array([])\n",
    "y_train_max = np.array([])\n",
    "y_train_min = np.array([])\n",
    "\n",
    "for i in data_train_y_list:\n",
    "    df = pd.read_csv(path+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    y_train_mean = np.append(y_train_mean, mean)\n",
    "    y_train_var = np.append(y_train_var, var)\n",
    "    y_train_std = np.append(y_train_std, std)\n",
    "    y_train_max = np.append(y_train_max, max)\n",
    "    y_train_min = np.append(y_train_min, min)\n",
    "\n",
    "y_train_feature = np.concatenate((y_train_mean.reshape(-1,1), y_train_var.reshape(-1,1), y_train_std.reshape(-1,1), y_train_max.reshape(-1,1), y_train_min.reshape(-1,1)), axis=1)\n",
    "y_train_feature.shape\n",
    "\n",
    "path = 'C:/Users/kbj/Downloads/data/train/z/'\n",
    "data_train_z_list = os.listdir('C:/Users/kbj/Downloads/data/train/z/')\n",
    "path = 'C:/Users/kbj/Downloads/data/train/z/'\n",
    "z_train_mean = np.array([])\n",
    "z_train_var = np.array([])\n",
    "z_train_std = np.array([])\n",
    "z_train_max = np.array([])\n",
    "z_train_min = np.array([])\n",
    "\n",
    "for i in data_train_z_list:\n",
    "    df = pd.read_csv(path+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    z_train_mean = np.append(z_train_mean, mean)\n",
    "    z_train_var = np.append(z_train_var, var)\n",
    "    z_train_std = np.append(z_train_std, std)\n",
    "    z_train_max = np.append(z_train_max, max)\n",
    "    z_train_min = np.append(z_train_min, min)\n",
    "\n",
    "z_train_feature = np.concatenate((z_train_mean.reshape(-1,1), z_train_var.reshape(-1,1), z_train_std.reshape(-1,1), z_train_max.reshape(-1,1), z_train_min.reshape(-1,1)), axis=1)\n",
    "z_train_feature.shape\n",
    "\n",
    "path = 'C:/Users/kbj/Downloads/data/train/e/'\n",
    "data_train_e_list = os.listdir('C:/Users/kbj/Downloads/data/train/e/')\n",
    "path = 'C:/Users/kbj/Downloads/data/train/e/'\n",
    "e_train_mean = np.array([])\n",
    "e_train_var = np.array([])\n",
    "e_train_std = np.array([])\n",
    "e_train_max = np.array([])\n",
    "e_train_min = np.array([])\n",
    "\n",
    "for i in data_train_e_list:\n",
    "    df = pd.read_csv(path+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    e_train_mean = np.append(e_train_mean, mean)\n",
    "    e_train_var = np.append(e_train_var, var)\n",
    "    e_train_std = np.append(e_train_std, std)\n",
    "    e_train_max = np.append(e_train_max, max)\n",
    "    e_train_min = np.append(e_train_min, min)\n",
    "\n",
    "e_train_feature = np.concatenate((e_train_mean.reshape(-1,1), e_train_var.reshape(-1,1), e_train_std.reshape(-1,1), e_train_max.reshape(-1,1), e_train_min.reshape(-1,1)), axis=1)\n",
    "e_train_feature.shape\n",
    "\n",
    "#xyz_train_feature = np.sqrt(np.square(x_train_feature[:,0])+np.square(y_train_feature[:,0])+np.square(z_train_feature[:,0]))\n",
    "#xyz_train_feature = xyz_train_feature.reshape(-1,1)\n",
    "#all_train_feature = np.concatenate((x_train_feature, y_train_feature, z_train_feature, e_train_feature, xyz_train_feature), axis=1)\n",
    "all_train_feature = np.concatenate((x_train_feature, y_train_feature, z_train_feature, e_train_feature), axis=1)\n",
    "all_train_feature.shape\n",
    "\n",
    "train_label = pd.read_csv('C:/Users/kbj/Downloads/data/train/train_label.csv', header=None)\n",
    "train_label = train_label.to_numpy()\n",
    "\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 5)\n",
      "(1400, 5)\n",
      "(1400, 5)\n",
      "(1400, 5)\n",
      "(1400, 20)\n",
      "(1400, 1)\n"
     ]
    }
   ],
   "source": [
    "path_x = 'C:/Users/kbj/Downloads/data/test/x/'\n",
    "data_test_x_list = os.listdir('C:/Users/kbj/Downloads/data/test/x/')\n",
    "x_test_mean = np.array([])\n",
    "x_test_var = np.array([])\n",
    "x_test_std = np.array([])\n",
    "x_test_max = np.array([])\n",
    "x_test_min = np.array([])\n",
    "\n",
    "for i in data_test_x_list:\n",
    "    df = pd.read_csv(path_x+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    x_test_mean = np.append(x_test_mean, mean)\n",
    "    x_test_var = np.append(x_test_var, var)\n",
    "    x_test_std = np.append(x_test_std, std)\n",
    "    x_test_max = np.append(x_test_max, max)\n",
    "    x_test_min = np.append(x_test_min, min)\n",
    "\n",
    "x_test_feature = np.concatenate((x_test_mean.reshape(-1,1), x_test_var.reshape(-1,1), x_test_std.reshape(-1,1), x_test_max.reshape(-1,1), x_test_min.reshape(-1,1)), axis=1)\n",
    "print(x_test_feature.shape)\n",
    "\n",
    "path_y = 'C:/Users/kbj/Downloads/data/test/y/'\n",
    "data_test_y_list = os.listdir('C:/Users/kbj/Downloads/data/test/y/')\n",
    "y_test_mean = np.array([])\n",
    "y_test_var = np.array([])\n",
    "y_test_std = np.array([])\n",
    "y_test_max = np.array([])\n",
    "y_test_min = np.array([])\n",
    "\n",
    "for i in data_test_y_list:\n",
    "    df = pd.read_csv(path_y+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    y_test_mean = np.append(y_test_mean, mean)\n",
    "    y_test_var = np.append(y_test_var, var)\n",
    "    y_test_std = np.append(y_test_std, std)\n",
    "    y_test_max = np.append(y_test_max, max)\n",
    "    y_test_min = np.append(y_test_min, min)\n",
    "\n",
    "y_test_feature = np.concatenate((y_test_mean.reshape(-1,1), y_test_var.reshape(-1,1), y_test_std.reshape(-1,1), y_test_max.reshape(-1,1), y_test_min.reshape(-1,1)), axis=1)\n",
    "print(y_test_feature.shape)\n",
    "\n",
    "path_z = 'C:/Users/kbj/Downloads/data/test/z/'\n",
    "data_test_z_list = os.listdir('C:/Users/kbj/Downloads/data/test/z/')\n",
    "z_test_mean = np.array([])\n",
    "z_test_var = np.array([])\n",
    "z_test_std = np.array([])\n",
    "z_test_max = np.array([])\n",
    "z_test_min = np.array([])\n",
    "\n",
    "for i in data_test_z_list:\n",
    "    df = pd.read_csv(path_z+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    z_test_mean = np.append(z_test_mean, mean)\n",
    "    z_test_var = np.append(z_test_var, var)\n",
    "    z_test_std = np.append(z_test_std, std)\n",
    "    z_test_max = np.append(z_test_max, max)\n",
    "    z_test_min = np.append(z_test_min, min)\n",
    "\n",
    "z_test_feature = np.concatenate((z_test_mean.reshape(-1,1), z_test_var.reshape(-1,1), z_test_std.reshape(-1,1), z_test_max.reshape(-1,1), z_test_min.reshape(-1,1)), axis=1)\n",
    "print(z_test_feature.shape)\n",
    "\n",
    "path_e = 'C:/Users/kbj/Downloads/data/test/e/'\n",
    "data_test_e_list = os.listdir('C:/Users/kbj/Downloads/data/test/e/')\n",
    "e_test_mean = np.array([])\n",
    "e_test_var = np.array([])\n",
    "e_test_std = np.array([])\n",
    "e_test_max = np.array([])\n",
    "e_test_min = np.array([])\n",
    "\n",
    "for i in data_test_e_list:\n",
    "    df = pd.read_csv(path_e+i, header=None)\n",
    "    mean = np.mean(df.to_numpy())\n",
    "    var = np.var(df.to_numpy())\n",
    "    std = np.std(df.to_numpy())\n",
    "    max = np.max(df.to_numpy())\n",
    "    min = np.min(df.to_numpy())\n",
    "    e_test_mean = np.append(e_test_mean, mean)\n",
    "    e_test_var = np.append(e_test_var, var)\n",
    "    e_test_std = np.append(e_test_std, std)\n",
    "    e_test_max = np.append(e_test_max, max)\n",
    "    e_test_min = np.append(e_test_min, min)\n",
    "\n",
    "e_test_feature = np.concatenate((e_test_mean.reshape(-1,1), e_test_var.reshape(-1,1), e_test_std.reshape(-1,1), e_test_max.reshape(-1,1), e_test_min.reshape(-1,1)), axis=1)\n",
    "print(e_test_feature.shape)\n",
    "\n",
    "#xyz_test_feature = np.sqrt(np.square(x_test_feature[:,0])+np.square(y_test_feature[:,0])+np.square(z_test_feature[:,0]))\n",
    "#xyz_test_feature = xyz_test_feature.reshape(-1,1)\n",
    "#all_test_feature = np.concatenate((x_test_feature, y_test_feature, z_test_feature, e_test_feature, xyz_test_feature), axis=1)\n",
    "\n",
    "all_test_feature = np.concatenate((x_test_feature, y_test_feature, z_test_feature, e_test_feature), axis=1)\n",
    "print(all_test_feature.shape)\n",
    "\n",
    "test_label = pd.read_csv('C:/Users/kbj/Downloads/data/test/test_label.csv', header=None)\n",
    "test_label = test_label.to_numpy()\n",
    "\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 20)\n",
      "(700, 1)\n",
      "(1400, 20)\n",
      "(1400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(all_train_feature.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(all_test_feature.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_train_feature\n",
    "train_y = train_label.reshape(-1)\n",
    "test_x = all_test_feature\n",
    "test_y = test_label.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_x)\n",
    "\n",
    "x_train_std = sc.transform(train_x)\n",
    "x_test_std = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=8, gamma=0.1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=8, gamma=0.1)\n",
    "\n",
    "svm_model.fit(x_train_std, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.98357\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(x_test_std)\n",
    "\n",
    "print(\"prediction accuracy: {:.5f}\".format(np.mean(y_pred == test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196   0   1   0   0   0   3]\n",
      " [  1 194   4   0   0   0   1]\n",
      " [  2   0 194   3   0   0   1]\n",
      " [  0   0   0 200   0   0   0]\n",
      " [  0   0   0   0 200   0   0]\n",
      " [  0   0   0   0   0 200   0]\n",
      " [  4   3   0   0   0   0 193]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(all_train_feature)\n",
    "train_y = torch.LongTensor(train_label.reshape(-1))\n",
    "test_x = torch.Tensor(all_test_feature)\n",
    "test_y = torch.LongTensor(test_label.reshape(-1))\n",
    "\n",
    "ds_train = TensorDataset(train_x, train_y)\n",
    "ds_test = TensorDataset(test_x, test_y)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c644af2b13e56b04db7589c61fc8993524f91b02323464e25eb4a200df9a07b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
